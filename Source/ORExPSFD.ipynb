{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "168efbaa-c567-4e0a-9a45-445b32b43f12",
   "metadata": {},
   "source": [
    "# OSIRIS-REx: size analysis of sample OREX-800107-0\n",
    "OREX-800107-0 is a 6.4-gram aggregate sample that contains approximately 1.5 million grains."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10944797-1f03-4b64-918f-687064b1872c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import modules\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import skimage                            # used for image processing\n",
    "from scipy import ndimage                 # used to label all the grains\n",
    "import os                                 # used to interact with operating systems\n",
    "from scipy.spatial.distance import pdist  # pdist = pairwise distances\n",
    "from scipy.ndimage import find_objects\n",
    "from tabulate import tabulate\n",
    "from numba import jit, njit, prange\n",
    "from scipy.optimize import curve_fit      # used for power law plotting\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01a91b27-c67d-4cf3-a816-d181c9a37947",
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign variables to outputs from Ilastic\n",
    "\n",
    "# change for a different computer or a different Ilastik stack:\n",
    "\n",
    "# base_dir = 'C:\\\\Users\\\\savan'\n",
    "# folder = '\\\\107IlastikSample\\\\'\n",
    "# images = '\\\\107IlastikSample_{i:04d}.tif'\n",
    "\n",
    "# initialize an np.ndarray for data\n",
    "# NOTE: data may be interpreted in y, x, z\n",
    "cube = np.zeros((1384, 1390, 1751), dtype='int8')\n",
    "# loop through every slice in the xy plane\n",
    "for i in range(0,1719):\n",
    "    # data = open(os.path.join('C:', os.sep, 'Users', 'savan', '107IlastikSample', '107IlastikSample_{i:04d}.tif')).read()\n",
    "    # define a path to the Ilastik output\n",
    "    data = r'C:\\\\Users\\\\savan\\\\107IlastikSample' + f'/107IlastikSample_{i:04d}' + '.tif'  # address for laptop\n",
    "    # assign data to an np.ndarray\n",
    "    cube[:,:,i] = plt.imread(data)\n",
    "    # progress check:\n",
    "    if i % 10 == 0:\n",
    "       print(i, end='\\r')\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a8dc670-3178-4d2c-9b11-299b43d5e4f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# determine the voxel count of every class\n",
    "print(f'Phase 1 (particle): {np.sum(cube==1): 0.2g} voxels')\n",
    "print(f'Phase 2 (matrix): {np.sum(cube==2): 0.2g} voxels')\n",
    "print(f'Phase 3 (vessel): {np.sum(cube==3): 0.2g} voxels')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67cf63f5-797b-41ae-ba38-4756f0b18a08",
   "metadata": {},
   "source": [
    "Grainmask evaluation:\n",
    "--------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8699e96c-4f73-466b-8f2a-7a2bb91a29f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# form a grain mask based on the stored grains\n",
    "grainmask = (cube == 1).astype('uint8')\n",
    "\n",
    "# plot the grain mask at different z-slices:\n",
    "# can plot more of these to see how accurate Ilastik was in comparison to raw data\n",
    "# 0 represents matrix and 1 represents grain\n",
    "\n",
    "# these masks allow us to quickly analyze the accuracy of the Ilastik model\n",
    "# are the individual grains clear from these grain masks? \n",
    "# are there prominent places where grains have not been properly segmented?\n",
    "\n",
    "plt.figure('Grain Mask(400)', figsize=(15,15))\n",
    "plt.title('Grain Mask at z = 400')\n",
    "plt.imshow(grainmask[600:800,600:800,400])\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "\n",
    "plt.figure('Grain Mask (700)', figsize=(15,15))\n",
    "plt.title('Grain Mask at z = 700')\n",
    "plt.imshow(grainmask[600:800,600:800,700])\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "\n",
    "plt.figure('Grain Mask (1000)', figsize=(15,15))\n",
    "plt.title('Grain Mask at z = 1000')\n",
    "plt.imshow(grainmask[600:800,600:800,1000])\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "\n",
    "plt.figure('Grain Mask(1300)', figsize=(15,15))\n",
    "plt.title('Grain Mask at z = 1300', fontsize=30)\n",
    "plt.imshow(grainmask[600:800,600:800,1300])\n",
    "plt.colorbar()\n",
    "plt.savefig('GrainMask1300.png', dpi=300)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edaaeaa2-7c9a-4cb0-add2-38690fc91772",
   "metadata": {},
   "source": [
    "Using the grain mask in further variable definition:\n",
    "---------------------------------------------------\n",
    "The GrainLabelCube is an np.ndarray that will be used in all the following codes. This cube represents the 3D data set as segmented grains."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cc61f53-a600-4584-98b7-2df5ac579a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# determine the number of grains in the entire sample by counting individual islands\n",
    "# needs a lot of memory to run due to extremely large data set\n",
    "GrainLabelCube, NumLabel = ndimage.label(grainmask, None, output=np.uint32)\n",
    "print(f'there are {NumLabel} particles that are labeled')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4e1527e-3f78-45d6-a628-d2d08b6c5192",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the islands in the entire sample\n",
    "fig,ax = plt.subplots(1, 2, figsize=(15,15))\n",
    "ax[0].imshow(grainmask[:,500,:] == 1)\n",
    "ax[1].imshow(GrainLabelCube[:,500,:])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbf1da7e-0199-4c56-a65b-2c9963178961",
   "metadata": {},
   "source": [
    "Compute grain volume:\n",
    "---------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f70cf0b5-f2b4-4dfa-9a40-07d98d160c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit(parallel=True)     # using numba for speed\n",
    "\n",
    "def ComputeVolumes(GrainLabelCube):\n",
    "    '''\n",
    "        This function computes the volume of every grain with units of voxels\n",
    "        input:\n",
    "            GrainLabelCube: np.ndarray\n",
    "                stores the individual grai\n",
    "        output:\n",
    "            volumes: np.array\n",
    "                stores the volume of every grain in GrainLabelCube\n",
    "    '''\n",
    "\n",
    "    # intialize an np.array of size of NumLabel\n",
    "    volumes = np.zeros(NumLabel)\n",
    "    # turn np.ndarray to a 1D array\n",
    "    GrainRavel = np.ravel(GrainLabelCube)  \n",
    "\n",
    "    # loop through every voxel in GrainLabelCube through GrainRavel\n",
    "    for i in range(len(GrainRavel)):\n",
    "        volumes[GrainRavel[i]] += 1\n",
    "        \n",
    "    # first bin is background and is bigger than any other grain\n",
    "    volumes[0] = 0\n",
    "    \n",
    "    return volumes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8adc901-7f02-4555-80db-79f939774fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# assigning variable to ComputeVolumes output\n",
    "volumes = ComputeVolumes(GrainLabelCube)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53d69997-6b42-4f9a-a824-15d2ba1ef7a3",
   "metadata": {},
   "source": [
    "# Start of PSFD calculations:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caa97f03-0c38-428b-9999-65a9a65884da",
   "metadata": {},
   "source": [
    "Approximated longest axis calculation:\n",
    "--------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83a68f96-a15f-442b-9ed0-0ef2e0b95dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find_objects identifies and returns the bounding box coordinates for every labeled object\n",
    "# returns a list of tuples where the tuples contain the coordinates\n",
    "BoundingBoxes = ndimage.find_objects(GrainLabelCube)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c958eab-cef7-4165-ac19-7c29542993e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using a bounding box APPROXIMATION for the longest axis:\n",
    "\n",
    "def BBLongestAxis(GrainLabelCube):\n",
    "    '''\n",
    "        This function calculates an approximation of the longest axis of a grain \n",
    "        using a bounding box algorithm\n",
    "        input:\n",
    "            GrainLabelCube: np.ndarray\n",
    "                stores the individual grains\n",
    "        output:\n",
    "            BBLongestAxes: np.ndarray\n",
    "                stores an approx. of the longest axis of each grain\n",
    "    '''\n",
    "\n",
    "    # initialize an np.array to add longest axes calculations\n",
    "    BBLongestAxes = np.zeros(NumLabel)\n",
    "\n",
    "    # loop through each grain's bounding box\n",
    "    for i, BoundingBox in enumerate(BoundingBoxes):\n",
    "\n",
    "        # if bounding box is empty, move to the next bounding box\n",
    "        if BoundingBox is None:\n",
    "            continue\n",
    "\n",
    "        # find the bounding box vertex coordinates\n",
    "        MinCoord = np.array([BoundingBox[j].start for j in range(len(BoundingBox))])\n",
    "        MaxCoord = np.array([BoundingBox[j].stop for j in range(len(BoundingBox))])\n",
    "\n",
    "        # find the distance between the two vertex coordinates\n",
    "        ApproxLongestAxis = np.linalg.norm(MaxCoord - MinCoord)\n",
    "\n",
    "        # add the approximated axis to np.array\n",
    "        # multiply value by 0.017 because each voxel is 0.017 mm\n",
    "        BBLongestAxes[i] = ApproxLongestAxis * 0.017\n",
    "\n",
    "    return BBLongestAxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c15b1674-daa1-427d-abd2-05069f4aab77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# assigning variable to BBLongestAxis output\n",
    "BBLongestAxes = BBLongestAxis(GrainLabelCube)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3bd077d-4f8e-43b8-b280-4012a3c87a0c",
   "metadata": {},
   "source": [
    "Importing the Dragonfly data from the csv file from Andy\n",
    "--------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7db3f54-f7d8-438c-a43b-064052eca479",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the CSV file\n",
    "DragonflyData = pd.read_csv('orex-800107-0_segmented_stats.csv', delimiter=';', encoding='utf-8')\n",
    "\n",
    "#print(DragonflyData.head())\n",
    "\n",
    "#print(DragonflyData.columns.tolist())\n",
    "\n",
    "FeretMin = DragonflyData['Min Feret Diameter (mm)']\n",
    "FeretMax = DragonflyData['Max Feret Diameter (mm)']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b78a28e-41f1-4da7-8e7a-6d708c8ff6e6",
   "metadata": {},
   "source": [
    "Plotting the approximation:\n",
    "--------------------------\n",
    "Consider cutting off grain size at roughly 5 voxel or 0.065 mm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b361464-ece3-42c6-9c0e-f797f5def54b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def PowerLaw(x, a, b):\n",
    "    '''\n",
    "        This function computes the power law of a given data set\n",
    "        inputs:\n",
    "            x: np.array\n",
    "                the data (longest axes of particles)\n",
    "            a: float\n",
    "                the y-intercept of the power-law fit\n",
    "            b: float\n",
    "                the slope of the power-law fit\n",
    "        outputs: \n",
    "            PL: float\n",
    "                the power law\n",
    "    '''\n",
    "    \n",
    "    PL = a * x ** b\n",
    "\n",
    "    return PL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fa018e9-6c83-4379-89cb-51a570d07250",
   "metadata": {},
   "source": [
    "From Burke+2021:\n",
    "----------------\n",
    "Power-law PSFDs with the form:\n",
    "\\begin{equation}\n",
    "    N_C = c D^{-a}\n",
    "\\end{equation}\n",
    "where $N_C$ is the cumulative number of particles greater than or equal to $D$ per surface area unit. $D$ is the longest axis particle measurement, $a$ is the power-law index, and $c$ is the coefficient of proportionality.\n",
    "- error from one PSFD came from the square root of $N_C$ which represents the Poisson detection distribution uncertainty."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abcab098-07f8-469c-9f08-8c588e942ca3",
   "metadata": {},
   "source": [
    "From Clauset+2009:\n",
    "-----------------\n",
    "Power-law MLE slope for continuous data:\n",
    "\\begin{equation}\n",
    "    \\hat{\\alpha} = 1 + n[\\sum_{i=1}^n ln(x_i/x_{min})]^{-1}\n",
    "\\end{equation}\n",
    "where $x_i$ are the data points greater than or equal to $x_{min}$ and $n$ is the number of those points\n",
    "So, the standard error is as follows:\n",
    "\\begin{equation}\n",
    "    \\sigma = (\\hat{\\alpha}-1) / \\sqrt{n}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e4cac17-43ba-4a9c-8cba-95819bdcc51f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using information from Clauset+2009:\n",
    "# note: maybe use this or continue to use the bootstrap uncertainty calc\n",
    "def powerlaw_slope_and_error(x, x_min):\n",
    "    x_cut = x[x >= x_min]\n",
    "    n = len(x_cut)\n",
    "    alpha = 1 + n / np.sum(np.log(x_cut / x_min))\n",
    "    sigma = (alpha - 1) / np.sqrt(n)\n",
    "    return alpha, sigma"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acef42cf-23ee-40a6-94a4-1cdb372444f9",
   "metadata": {},
   "source": [
    "# Plotting PSFD:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3b63069-3b5a-41a5-9fab-165233a4814c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NO ERROR CALCULATION\n",
    "\n",
    "# hard-code total analyzed volume of the sample\n",
    "# used to normalize the counts\n",
    "SampleVolume = 1e5   # in mm^3\n",
    "\n",
    "# define the x-range for fitting the linear slope accurately\n",
    "xmin_fit = 0.3\n",
    "xmax_fit = 3.0\n",
    "\n",
    "# create log-spaced bins for histogram plotting\n",
    "bins = np.logspace(np.log10(min(BBLongestAxes)), np.log10(max(BBLongestAxes)), 10000)\n",
    "counts, BinEdges = np.histogram(BBLongestAxes, bins=bins)\n",
    "# determining the cumulative sum from the smallest to the largest particle\n",
    "CumulativeCounts = np.cumsum(counts[::-1])[::-1] / SampleVolume  # per mm³\n",
    "BinCenters = (BinEdges[:-1] + BinEdges[1:]) / 2\n",
    "\n",
    "# ignore zeros in the counts due to loglog space\n",
    "mask = CumulativeCounts > 0\n",
    "x = BinCenters[mask]\n",
    "y = CumulativeCounts[mask]\n",
    "\n",
    "# mask the data to be within the selected x-range for accurate fitting\n",
    "# used to find the slope only based on the portion of the plot that is linear\n",
    "mask2 = (x >= xmin_fit) & (x <= xmax_fit)\n",
    "x_fit = x[mask2]\n",
    "y_fit = y[mask2]\n",
    "\n",
    "# fit the curve to the dataset\n",
    "parameters, _ = curve_fit(PowerLaw, x_fit, y_fit, p0=[0.12, -2])\n",
    "a, b = parameters\n",
    "\n",
    "# compute y=mx+b line for slope\n",
    "x_line = np.logspace(np.log10(xmin_fit), np.log10(xmax_fit), 100)\n",
    "y_line = PowerLaw(x_line, a, b)\n",
    "\n",
    "# plot the PSFD\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.loglog(x, y, 'o', ms=1, label='Cumulative Number\\nof Particles', color='black')\n",
    "# highlight portion of the data that contributes to the slope\n",
    "plt.loglog(x_fit, y_fit, 'o', ms=1, color='yellowgreen')\n",
    "plt.loglog(x_line, y_line, ls='--', ms=10, label=f\"Slope = {b:.2f}\", color='green')\n",
    "# labels and organization\n",
    "plt.xlabel(\"BB Longest Axis (mm)\", fontsize=13).set_style('italic')\n",
    "plt.ylabel(f\"Cumulative Frequency per $mm^3$\", fontsize=13).set_style('italic')\n",
    "plt.title(\"Appromixated Particle Size Frequency Distribution\\n for sample OREX-800107-0 using Ilastik\", fontsize=14, weight='bold')\n",
    "plt.grid(True, which='both', linestyle=':', linewidth=0.5)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig('PSFD107_Ilastik_approx.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3ffdefe-8b03-4b4e-9fff-1b067d637de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CALCULATING ERROR WITH A POISSON DISTRIBUTION\n",
    "\n",
    "# hard-code total analyzed volume of the sample\n",
    "# used to normalize the counts\n",
    "SampleVolume = 1e5   # in mm^3\n",
    "\n",
    "# define the x-range for fitting the linear slope accurately\n",
    "xmin_fit = 0.3\n",
    "xmax_fit = 3.0\n",
    "\n",
    "# create log-spaced bins for histogram plotting\n",
    "bins = np.logspace(np.log10(min(BBLongestAxes)), np.log10(max(BBLongestAxes)), 1000)\n",
    "counts, BinEdges = np.histogram(BBLongestAxes, bins=bins)\n",
    "# determine the cumulative sum from the smallest to the largest particle\n",
    "CumulativeCounts = np.cumsum(counts[::-1])[::-1] / SampleVolume  # per mm^3\n",
    "BinCenters = (BinEdges[:-1] + BinEdges[1:]) / 2\n",
    "\n",
    "# ignore zeros in the counts due to loglog space\n",
    "mask = CumulativeCounts > 0\n",
    "x = BinCenters[mask]\n",
    "y = CumulativeCounts[mask]\n",
    "\n",
    "# mask the data to be within the selected x-range for accurate fitting\n",
    "# used to find the slope only based on the portion of the plot that is linear\n",
    "mask2 = (x >= xmin_fit) & (x <= xmax_fit)\n",
    "x_fit = x[mask2]\n",
    "y_fit = y[mask2]\n",
    "\n",
    "# fit the curve to the dataset\n",
    "parameters, _ = curve_fit(PowerLaw, x_fit, y_fit, p0=[0.12, -2])\n",
    "a, b = parameters\n",
    "\n",
    "# compute y=mx+b line for slope\n",
    "x_line = np.logspace(np.log10(xmin_fit), np.log10(xmax_fit), 100)\n",
    "y_line = PowerLaw(x_line, a, b)\n",
    "\n",
    "# compute standard deviation of cumulative counts using poisson distribution uncertainty\n",
    "errors = np.sqrt(y) / SampleVolume  # SD per mm^3\n",
    "# compute log-scale error (for log-log plots)\n",
    "# note: when this is plotted with the PSFD, the plot is incorrect... \n",
    "# unsure if this is due to a math error or a data error...\n",
    "log_errors = (1 / np.log(10)) * (1 / np.sqrt(y))  \n",
    "\n",
    "# plot the PSFD\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.loglog(x, y, 'o', ms=1, label='Cumulative Number\\nof Particles', color='black')\n",
    "# highlight portion of the data that contributes to the slope\n",
    "plt.loglog(x_fit, y_fit, 'o', ms=1, color='yellowgreen')\n",
    "plt.loglog(x_line, y_line, ls='--', ms=10, label=f\"Slope = {b:.2f}\", color='green')\n",
    "\n",
    "# plot error bars on cumulative counts\n",
    "# corresponds to uncertainty in the cumulative frequency\n",
    "plt.errorbar(x, y, yerr=errors, fmt='none', ecolor='gray', alpha=0.3, capsize=1, label='Error')\n",
    "\n",
    "# labels and organization\n",
    "plt.xlabel(\"BB Longest Axis (mm)\", fontsize=13).set_style('italic')\n",
    "plt.ylabel(f\"Cumulative Frequency per $mm^3$\", fontsize=13).set_style('italic')\n",
    "plt.title(\"Appromixated Particle Size Frequency Distribution\\n for sample OREX-800107-0 using Ilastik\", fontsize=14, weight='bold')\n",
    "plt.grid(True, which='both', linestyle=':', linewidth=0.5)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig('PSFD107_Ilastik_approx_errors.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b71bb6d-3c38-4611-8b27-54454856f58c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CALCULATING ERROR WITH BOOTSTRAP METHOD FROM CLAUSSET ET AL.\n",
    "\n",
    "# hard-code total volume of the sample (approximated)\n",
    "SampleVolume = 1e5  # in mm^3\n",
    "\n",
    "# define the x-range for fitting the linear slope accurately\n",
    "xmin_fit = 0.3\n",
    "xmax_fit = 3.0\n",
    "\n",
    "# create log-spaced bins for histogram plotting\n",
    "bins = np.logspace(np.log10(min(BBLongestAxes)), np.log10(max(BBLongestAxes)), 10000)\n",
    "BinEdges, _ = np.histogram(BBLongestAxes, bins=bins)\n",
    "# determine the cumulative sum from the smallest to the largest particle\n",
    "CumulativeCounts = np.cumsum(BinEdges[::-1])[::-1] / SampleVolume  # per mm³\n",
    "BinCenters = (bins[:-1] + bins[1:]) / 2\n",
    "\n",
    "# remove zero counts to avoid log errors\n",
    "mask = CumulativeCounts > 0\n",
    "x = BinCenters[mask]\n",
    "y = CumulativeCounts[mask]\n",
    "\n",
    "# mask the values for the slope to those previously defined\n",
    "mask2 = (x >= xmin_fit) & (x <= xmax_fit)\n",
    "x_fit = x[mask2]\n",
    "y_fit = y[mask2]\n",
    "\n",
    "# fit original data to get initial slope\n",
    "parameteres, _ = curve_fit(PowerLaw, x_fit, y_fit, p0=[0.1, -2.1])\n",
    "a_fit, b_fit = parameters\n",
    "\n",
    "# compute the slope line for plotting\n",
    "x_line = np.logspace(np.log10(xmin_fit), np.log10(xmax_fit), 100)\n",
    "y_line = PowerLaw(x_line, a_fit, b_fit)\n",
    "\n",
    "# loop through slope values to find uncertainty\n",
    "B = 1000  # use at least 5000 for jounral accuracy\n",
    "BootstrapSlopes = []\n",
    "\n",
    "for i in range(B):\n",
    "    # create a randomized data set\n",
    "    # less biased towards one part of the data\n",
    "    sample = np.random.choice(BBLongestAxes, size=len(BBLongestAxes), replace=True)\n",
    "    \n",
    "    # compute histogram and cumulative counts with randomized data\n",
    "    bins = np.logspace(np.log10(min(sample)), np.log10(max(sample)), 10000)\n",
    "    BinEdges, i = np.histogram(sample, bins=bins)\n",
    "    CumulativeCounts = np.cumsum(BinEdges[::-1])[::-1] / SampleVolume\n",
    "    BinCenters = (bins[:-1] + bins[1:]) / 2\n",
    "\n",
    "    # ensure there are no zero counts for log space\n",
    "    mask3 = CumulativeCounts > 0\n",
    "    x_bootstrap = BinCenters[mask3]\n",
    "    y_bootstrap = CumulativeCounts[mask3]\n",
    "\n",
    "    # ensure the x and y values are within the ranges for best-fit\n",
    "    mask4 = (x_bootstrap >= xmin_fit) & (x_bootstrap <= xmax_fit)\n",
    "    x_fit_bootstrap = x_bootstrap[mask4]\n",
    "    y_fit_bootstrap = y_bootstrap[mask4]\n",
    "\n",
    "    # try to fit the above power law to the bootstrap data\n",
    "    try:\n",
    "        parameters_bootstrap, _ = curve_fit(PowerLaw, x_fit_bootstrap, y_fit_bootstrap, p0=[0.1, -2.1])\n",
    "        a_bootstrap, b_bootstrap = parameters_bootstrap\n",
    "        BootstrapSlopes.append(b_bootstrap)\n",
    "    # if the fit fails, move to the next bootstrap value\n",
    "    except:\n",
    "        continue \n",
    "\n",
    "# convert list to np array\n",
    "BootstrapSlopes = np.array(BootstrapSlopes)\n",
    "mean_slope = np.mean(BootstrapSlopes)\n",
    "# define confidence intervals\n",
    "# will determine the +/- error for the slope\n",
    "confidence_lower = np.percentile(BootstrapSlopes, 2.5)  # can change these percentiles\n",
    "confidence_upper = np.percentile(BootstrapSlopes, 97.5)\n",
    "\n",
    "# plot the PSFD\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.loglog(x, y, '.', ms=1, label='Cumulative Number\\nof Particles', color='black')\n",
    "# highlight the region of the data that corresponds to the best-fit slope\n",
    "plt.loglog(x_fit, y_fit, 'o', ms=1, color='yellowgreen')\n",
    "\n",
    "# plot best fit slope with bootstrap uncertainty\n",
    "plt.loglog(x_line, y_line, '--', ms=5, \n",
    "           label=f\"Slope = {b_fit:.2f}\\n95% confidence interval: [{confidence_lower:.2f}, {confidence_upper:.2f}]\", color='green')\n",
    "\n",
    "# labels and organization\n",
    "plt.xlabel('BB Longest Axis (mm)', fontsize=13).set_style('italic')\n",
    "plt.ylabel('Cumulative Frequency per mm$^3$', fontsize=13).set_style('italic')\n",
    "plt.title(\"Approximated Particle Size Frequency Distribution\\nfor Sample OREX-800107-0 Using Ilastik\", fontsize=14, weight='bold')\n",
    "plt.grid(which='both', linestyle=':', linewidth=0.5)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig('PSFD107_Ilastik_bootstrap.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e4337b-af03-42b2-a845-cffbbcdaf2c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make an approximated particle number table\n",
    "\n",
    "# define bins for the particle size range\n",
    "bins = [0.01, 0.02, 0.03, 0.05, 0.07, 0.1, 0.2, 0.5, 0.8, 1.0, 2.0, 3.0, 5.0, 7.0]  \n",
    "labels = [f\"{bins[i]}-{bins[i+1]}\" for i in range(len(bins) - 1)]\n",
    "\n",
    "# count the number of particles in each bin\n",
    "counts, _ = np.histogram(BBLongestAxes, bins=bins)\n",
    "\n",
    "# create table data\n",
    "table = list(zip(labels, counts))\n",
    "\n",
    "print(tabulate(table, headers=[\"Size Range (mm)\", \"Number of Particles\"], tablefmt=\"simple\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df91cdf2-8c55-43fc-a7c1-2912fdb8c9df",
   "metadata": {},
   "source": [
    "Plotting using Dragonfly:\n",
    "-------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1823993-f5bf-4ff9-8538-b8c3d47318e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NO ERROR CALCULATION\n",
    "\n",
    "# hard-code total analyzed volume of the sample\n",
    "# used to normalize the counts\n",
    "SampleVolume = 1e5   # in mm^3\n",
    "\n",
    "# define the x-range for fitting the linear slope accurately\n",
    "xmin_fit = 0.5\n",
    "xmax_fit = 2.0\n",
    "\n",
    "# create log-spaced bins for histogram plotting\n",
    "bins = np.logspace(np.log10(min(FeretMax)), np.log10(max(FeretMax)), 10000)\n",
    "counts, BinEdges = np.histogram(FeretMax, bins=bins)\n",
    "# determining the cumulative sum from the smallest to the largest particle\n",
    "CumulativeCounts = np.cumsum(counts[::-1])[::-1] / SampleVolume  # per mm³\n",
    "BinCenters = (BinEdges[:-1] + BinEdges[1:]) / 2\n",
    "\n",
    "# ignore zeros in the counts due to loglog space\n",
    "mask = CumulativeCounts > 0\n",
    "x = BinCenters[mask]\n",
    "y = CumulativeCounts[mask]\n",
    "\n",
    "# mask the data to be within the selected x-range for accurate fitting\n",
    "# used to find the slope only based on the portion of the plot that is linear\n",
    "mask2 = (x >= xmin_fit) & (x <= xmax_fit)\n",
    "x_fit = x[mask2]\n",
    "y_fit = y[mask2]\n",
    "\n",
    "# fit the curve to the dataset\n",
    "parameters, _ = curve_fit(PowerLaw, x_fit, y_fit, p0=[0.12, -2])\n",
    "a, b = parameters\n",
    "\n",
    "# compute y=mx+b line for slope\n",
    "x_line = np.logspace(np.log10(xmin_fit), np.log10(xmax_fit), 100)\n",
    "y_line = PowerLaw(x_line, a, b)\n",
    "\n",
    "# plot the PSFD\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.loglog(x, y, 'o', ms=1, label='Cumulative Number\\nof Particles', color='black')\n",
    "# highlight portion of the data that contributes to the slope\n",
    "plt.loglog(x_fit, y_fit, 'o', ms=1, color='turquoise')\n",
    "plt.loglog(x_line, y_line, ls='--', ms=10, label=f\"Slope = {b:.2f}\", color='blue')\n",
    "# labels and organization\n",
    "plt.xlabel(\"Maximum Feret Diameter (mm)\", fontsize=13).set_style('italic')\n",
    "plt.ylabel(f\"Cumulative Frequency per $mm^3$\", fontsize=13).set_style('italic')\n",
    "plt.title(\"Particle Size Frequency Distribution\\n for sample OREX-800107-0 using Dragonfly\", fontsize=14, weight='bold')\n",
    "plt.grid(True, which='both', linestyle=':', linewidth=0.5)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "plt.savefig('PSFD107_Dragonfly.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbe13d83-07cb-4c0b-8952-d126d13cee5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CALCULATING ERROR USING POSSION DISTRIBUTION\n",
    "\n",
    "# hard-code total analyzed volume of the sample\n",
    "# used to normalize the counts\n",
    "SampleVolume = 1e5   # in mm^3\n",
    "\n",
    "# define the x-range for fitting the linear slope accurately\n",
    "xmin_fit = 0.5\n",
    "xmax_fit = 2.0\n",
    "\n",
    "# create log-spaced bins for histogram plotting\n",
    "bins = np.logspace(np.log10(min(FeretMax)), np.log10(max(FeretMax)), 10000)\n",
    "counts, BinEdges = np.histogram(FeretMax, bins=bins)\n",
    "# determining the cumulative sum from the smallest to the largest particle\n",
    "CumulativeCounts = np.cumsum(counts[::-1])[::-1] / SampleVolume  # per mm³\n",
    "BinCenters = (BinEdges[:-1] + BinEdges[1:]) / 2\n",
    "\n",
    "# ignore zeros in the counts due to loglog space\n",
    "mask = CumulativeCounts > 0\n",
    "x = BinCenters[mask]\n",
    "y = CumulativeCounts[mask]\n",
    "\n",
    "# mask the data to be within the selected x-range for accurate fitting\n",
    "# used to find the slope only based on the portion of the plot that is linear\n",
    "mask2 = (x >= xmin_fit) & (x <= xmax_fit)\n",
    "x_fit = x[mask2]\n",
    "y_fit = y[mask2]\n",
    "\n",
    "# fit the curve to the dataset\n",
    "parameters, _ = curve_fit(PowerLaw, x_fit, y_fit, p0=[0.12, -2])\n",
    "a, b = parameters\n",
    "\n",
    "# compute y=mx+b line for slope\n",
    "x_line = np.logspace(np.log10(xmin_fit), np.log10(xmax_fit), 100)\n",
    "y_line = PowerLaw(x_line, a, b)\n",
    "\n",
    "# compute standard deviation of cumulative counts\n",
    "errors = np.sqrt(y) / SampleVolume  # SD per mm^3\n",
    "# compute log-scale error\n",
    "# note: same plotting issue occurs as with Ilastik model...\n",
    "log_errors = (1 / np.log(10)) * (1 / np.sqrt(y))\n",
    "\n",
    "# plot the PSFD\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.loglog(x, y, 'o', ms=1, label='Cumulative Number\\nof Particles', color='black')\n",
    "# highlight portion of the data that contributes to the slope\n",
    "plt.loglog(x_fit, y_fit, 'o', ms=1, color='turquoise')\n",
    "plt.loglog(x_line, y_line, ls='--', ms=10, label=f\"Slope = {b:.2f}\", color='blue')\n",
    "\n",
    "# plot error bars on cumulative counts\n",
    "plt.errorbar(x, y, yerr=errors, fmt='none', ecolor='gray', alpha=0.2, capsize=1, label='Error')\n",
    "\n",
    "# labels and organization\n",
    "plt.xlabel(\"Maximum Feret Diameter (mm)\", fontsize=13).set_style('italic')\n",
    "plt.ylabel(f\"Cumulative Frequency per $mm^3$\", fontsize=13).set_style('italic')\n",
    "plt.title(\"Particle Size Frequency Distribution\\n for sample OREX-800107-0 using Dragonfly\", fontsize=14, weight='bold')\n",
    "plt.grid(True, which='both', linestyle=':', linewidth=0.5)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig('PSFD107_Dragonfly_errors.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb4d2528-c82f-4892-9572-57680dd4f4d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make an approximated particle number table for Dragonfly\n",
    "\n",
    "# define bins for the particle size range\n",
    "# 0.01 mm is roughly 1 voxel\n",
    "# 0.151 mm is the size of the smallest particle in the Dragonfly dataset\n",
    "bins = [0.01, 0.15, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0, 1.5, 2.0, 3.0, 5.0, 7.0]  \n",
    "labels = [f\"{bins[i]}-{bins[i+1]}\" for i in range(len(bins) - 1)]\n",
    "\n",
    "# count the number of particles in each bin\n",
    "counts, _ = np.histogram(FeretMax, bins=bins)\n",
    "\n",
    "# create table data\n",
    "table = list(zip(labels, counts))\n",
    "\n",
    "print(tabulate(table, headers=[\"Size Range (mm)\", \"Number of Particles\"], tablefmt=\"simple\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ddc0ff1-c0bc-4651-8291-d3ed73111980",
   "metadata": {},
   "source": [
    "Actual longest grain calculation:\n",
    "--------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a710a80f-fb93-428f-a22f-df8d197f7308",
   "metadata": {},
   "outputs": [],
   "source": [
    "# counting the grain voxels within a bounding box (NOT an approximation):\n",
    "# note: requires even more memory than labeling every particle\n",
    "\n",
    "def LongestAxis(GrainLabelCube):\n",
    "    \n",
    "    # initialize an array to add largest axes calculations\n",
    "    LongestAxes = np.zeros(NumLabel)\n",
    "    \n",
    "    # loop through each bounding box region\n",
    "    for i, BoundingBox in enumerate(BoundingBoxes):\n",
    "    \n",
    "        # if bounding box is empty, move to the next bounding box\n",
    "        if BoundingBox is None:\n",
    "            continue\n",
    "            \n",
    "        # define the region of the bounding box\n",
    "        BoundedRegion = GrainLabelCube[BoundingBox]\n",
    "        # find the grain coordinates inside of the bounding box\n",
    "        GrainCoord = np.nonzero(BoundedRegion)\n",
    "        '''\n",
    "        # if no voxels are found, move to next grain\n",
    "        if GrainCoord.shape[0] == 0:\n",
    "            continue\n",
    "        '''\n",
    "        # determine the pairwise distances between every grain voxel in the bounding box\n",
    "        VoxelDistances = pdist(GrainCoord, metric='euclidean')\n",
    "\n",
    "        # loop through every pairwise distance found\n",
    "        if VoxelDistances.size > 0:  # ensures that there are distances\n",
    "            LongestAxes[i] = np.max(VoxelDistances)  # adds the largest distance to the list of longest axes\n",
    "    \n",
    "    return LongestAxes\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5eda608-fa47-406d-b8c5-6f62f0f13f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "LongestAxes = LongestAxis(GrainLabelCube)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82a62732-88ad-4c95-9cb4-530ca9d3cf93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot PSFD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a85d888b-cfb5-4b44-9488-ad623dab661a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make particle number table\n",
    "\n",
    "# define bins for the particle size range\n",
    "bins = [0.01, 0.05, 0.1, 0.2, 0.5, 0.8, 1.0, 2.0, 3.0, 5.0, 7.0]  \n",
    "labels = [f\"{bins[i]}-{bins[i+1]}\" for i in range(len(bins) - 1)]\n",
    "\n",
    "# count the number of particles in each bin\n",
    "counts, _ = np.histogram(LongestAxes, bins=bins)\n",
    "\n",
    "# create table data\n",
    "table = list(zip(labels, counts))\n",
    "\n",
    "print(tabulate(table, headers=[\"Size Range (mm)\", \"Number of Particles\"], tablefmt=\"simple\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "facba805-3b90-4605-938e-be1ef03d2a05",
   "metadata": {},
   "source": [
    "# Determining the Shape Characteristics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfcbabd4-2547-4b81-9292-84471fa88745",
   "metadata": {},
   "source": [
    "For sphericity:\n",
    "---------------\n",
    "Use Krumbein's formula for a 3D bounding box:\n",
    "\\begin{equation}\n",
    "\\Psi = (bc/(a^2))^{1/3}\n",
    "\\end{equation}\n",
    "where a, b, and c are the longest, intermediate, and shortest axes, respectively. If $\\Psi$ is 0, the grain is angular and if $\\Psi$ is 1, the grain is a perfect sphere."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4c9ee18-31e2-483b-b12c-d10b7253e2ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# note: wouldn't need this function if we don't use the bounding boxes for PSFD\n",
    "# inputs of the sphericity formula are the actual axes\n",
    "def GetBBDimensions(BoundingBoxes):\n",
    "    '''\n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ae1eb9-ea97-42b9-94df-0b4d2d447795",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Sphericity(a, b, c):\n",
    "    '''\n",
    "        This function computes the sphericity of a particle from its dimensions\n",
    "        inputs:\n",
    "            a: 'float'\n",
    "                longest particle axis\n",
    "            b: 'float'\n",
    "                intermediate particle axis\n",
    "            c: 'float'\n",
    "                smallest particle axis\n",
    "        output:\n",
    "            Sphericity: 'float'\n",
    "                variable representing the sphericity of the grain\n",
    "                0 for angular, 1 for perfect sphere\n",
    "        \n",
    "    '''\n",
    "\n",
    "    # make sure the axes are in decreasing length\n",
    "    a, b, c = sorted([a,b,c], reverse=True)\n",
    "\n",
    "    # calculating the numerator and denominator\n",
    "    num = b * c\n",
    "    den = a ** 2\n",
    "\n",
    "    Sphericity = (num/den) ** (1/3)\n",
    "\n",
    "    return Sphericity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "299a75e1-29de-4b49-8e4e-97860ee472cd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
