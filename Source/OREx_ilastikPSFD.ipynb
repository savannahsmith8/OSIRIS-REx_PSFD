{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1f77e764-aa22-41ed-923d-7a9886d736df",
   "metadata": {},
   "source": [
    "# OSIRIS-REx: particle size frequency distribution for OREX-800107-0 using size characteristics from ilastik\n",
    "OREX-800107-0 is a 6.4-gram aggregate sample that contains approximately 1.5 million grains. The parent sample was OREX-800013-0.\n",
    "This code analyzes the particle size frequency distribution (PSFD) using the outputs from the image processing software, ilastik. We trained a Random Forest machine learning algorithm using user annotations to process the XCT data. The segmentation from ilastik is loaded into this code and we use multiple Python libraries to find the segmented particles within the processed data. These isolated islands of voxels are analyzed to find the longest axis of the particle and then plot the PSFD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7378547-4274-4d5c-b25b-bb7b11a014c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import modules\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import skimage                            # used for image processing\n",
    "from scipy import ndimage                 # used to label all the grains\n",
    "import os                                 # used to interact with operating systems\n",
    "from scipy.spatial.distance import pdist  # pdist = pairwise distances\n",
    "from scipy.ndimage import find_objects\n",
    "from tabulate import tabulate\n",
    "from numba import jit, njit, prange\n",
    "from scipy.optimize import curve_fit      # used for power law plotting\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bf84b5d-957c-4950-8317-1a6556f6ed26",
   "metadata": {},
   "source": [
    "Load in the ilastik segmentation:\n",
    "--------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25eb5efc-3a01-46da-9b8d-2fd74837b959",
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign variables to outputs from Ilastic\n",
    "\n",
    "# initialize an numpy array for data\n",
    "# NOTE: data may be interpreted in y, x, z\n",
    "cube = np.zeros((1384, 1390, 1751), dtype='int8')\n",
    "# loop through every slice in the xy plane\n",
    "for i in range(0,1719):\n",
    "    # define a path to the ilastik output folder\n",
    "    data = r'C:\\\\Users\\\\savan\\\\OREX-800107-0_ilastik_segment' + f'/OREX-800107-0_ilastik_segment_{i:04d}' + '.tif'\n",
    "    # assign data to an np.ndarray\n",
    "    cube[:,:,i] = plt.imread(data)\n",
    "    # progress check:\n",
    "    if i % 10 == 0:\n",
    "       print(i, end='\\r')\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f4aecda-3dff-4d87-b195-b8fa7f3b4e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# determine the voxel count of every class\n",
    "print(f'Phase 1 (particle): {np.sum(cube==1): 0.3g} voxels')\n",
    "print(f'Phase 2 (matrix): {np.sum(cube==2): 0.3g} voxels')\n",
    "print(f'Phase 3 (vessel): {np.sum(cube==3): 0.3g} voxels')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e804869-768e-4a78-b4f4-d7089236b9b3",
   "metadata": {},
   "source": [
    "Evaluate the particle mask by plotting z-slices:\n",
    "--------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c26a23ba-155c-420c-bb57-52bacc9548f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# form a particle mask based on the stored particles\n",
    "ParticleMask = (cube == 1).astype('uint8')\n",
    "\n",
    "# plot the grain mask at different z-slices:\n",
    "# can plot more of these to see how accurate Ilastik was in comparison to raw data\n",
    "# 0 represents matrix and 1 represents particle\n",
    "\n",
    "# these masks allow us to quickly analyze the accuracy of the ilastik model\n",
    "# are the individual grains clear from these grain masks? \n",
    "# are there prominent places where grains have not been properly segmented?\n",
    "\n",
    "plt.figure('Particle Mask (400)', figsize=(15,15))\n",
    "plt.title('Particle Mask at z = 400', fontsize=30)\n",
    "plt.imshow(ParticleMask[600:800,600:800,400])\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "\n",
    "plt.figure('Particle Mask (700)', figsize=(15,15))\n",
    "plt.title('Particle Mask at z = 700', fontsize=30)\n",
    "plt.imshow(ParticleMask[600:800,600:800,700])\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "\n",
    "plt.figure('Particle Mask (1000)', figsize=(15,15))\n",
    "plt.title('Particle Mask at z = 1000', fontsize=30)\n",
    "plt.imshow(ParticleMask[600:800,600:800,1000])\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "\n",
    "plt.figure('Particle Mask (1300)', figsize=(15,15))\n",
    "plt.title('Particle Mask at z = 1300', fontsize=30)\n",
    "plt.imshow(ParticleMask[600:800,600:800,1300])\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8e8eba5-a705-41d1-b32b-4dddc2ebe51c",
   "metadata": {},
   "source": [
    "Label every isolated particle:\n",
    "--------------------------------\n",
    "The ParticleLabelCube is an np.ndarray that will be used in the rest of the script. This cube represents the 3D data set as segmented particles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0b0b4ff-23d9-4328-b380-7f52fd3465a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# determine the number of grains in the entire sample by counting individual islands\n",
    "# needs a lot of memory to run due to extremely large data set\n",
    "ParticleLabelCube, NumLabel = ndimage.label(ParticleMask, None, output=np.uint32)\n",
    "print(f'there are {NumLabel} particles that are labeled')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b0c48d4-0db5-46e9-bf53-1f217085d234",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the islands in the entire sample\n",
    "fig,ax = plt.subplots(1, 2, figsize=(15,15))\n",
    "ax[0].imshow(ParticleMask[:,500,:] == 1)\n",
    "ax[1].imshow(ParticleLabelCube[:,500,:])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "348a4938-bd22-4b72-99f4-85d2f3c3fcfc",
   "metadata": {},
   "source": [
    "Compute the volume of each particle:\n",
    "------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65fcfdd1-0415-4364-8337-ba34ed8cae13",
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit(parallel=True)     # using numba for speed\n",
    "\n",
    "def ComputeVolumes(ParticleLabelCube):\n",
    "    '''\n",
    "        This function computes the volume of every grain with units of voxels\n",
    "        input:\n",
    "            ParticleLabelCube: np.ndarray\n",
    "                stores the individual particle\n",
    "        output:\n",
    "            volumes: np.array\n",
    "                stores the volume of every particle in ParticleLabelCube\n",
    "    '''\n",
    "\n",
    "    # intialize an np.array of size of NumLabel\n",
    "    volumes = np.zeros(NumLabel)\n",
    "    # turn np.ndarray to a 1D array\n",
    "    ParticleRavel = np.ravel(ParticleLabelCube)  \n",
    "\n",
    "    # loop through every voxel in GrainLabelCube through GrainRavel\n",
    "    for i in range(len(ParticleRavel)):\n",
    "        volumes[ParticleRavel[i]] += 1\n",
    "        \n",
    "    # first bin is background and is bigger than any other grain\n",
    "    volumes[0] = 0\n",
    "    \n",
    "    return volumes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fb95615-ad6c-41f9-8206-29cf90705a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign variable to ComputeVolumes output\n",
    "volumes = ComputeVolumes(ParticleLabelCube)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35580504-21c5-470b-a815-1afdf256bc61",
   "metadata": {},
   "source": [
    "Identify the bounding box for every labeled particle:\n",
    "-----------------------------------------------------------------------------\n",
    "We use the find_objects function within the ndimage module of the SciPy library. This function identifies each island of voxels (an isolated particle) and returns the coordinates of the bounding box for every labeled particle. The function returns a list of tuples which contain the coordinates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c0230ab-76ec-4ccf-a7da-859992ba8443",
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign the bounding boxes to a variable\n",
    "BoundingBoxes = ndimage.find_objects(ParticleLabelCube)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14a9af08-8869-495e-9d43-34c238ed2327",
   "metadata": {},
   "source": [
    "Use the bounding boxes to approximate the longest axis of every particle:\n",
    "-------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52593fef-7a75-40db-8667-3a27d01bc506",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using a bounding box APPROXIMATION for the longest axis:\n",
    "\n",
    "def BBLongestAxis(NumLabel, BoundingBoxes):\n",
    "    '''\n",
    "        This function calculates an approximation of the longest axis of each particle \n",
    "        using a bounding box algorithm\n",
    "        input:\n",
    "            NumLabel: 'float'\n",
    "                the number of labeled particles\n",
    "            BoundingBoxes: list of tuples\n",
    "                a list of coordinates for the bounding boxes\n",
    "        output:\n",
    "            BBLongestAxes: np.ndarray\n",
    "                stores an approximated of the longest axis of each particle\n",
    "    '''\n",
    "\n",
    "    # initialize an np.array to add longest axes calculations\n",
    "    BBLongestAxes = np.zeros(NumLabel)\n",
    "\n",
    "    # loop through each grain's bounding box\n",
    "    for i, BoundingBox in enumerate(BoundingBoxes):\n",
    "\n",
    "        # if bounding box is empty, move to the next bounding box\n",
    "        if BoundingBox is None:\n",
    "            continue\n",
    "\n",
    "        # find the bounding box vertex coordinates\n",
    "        MinCoord = np.array([BoundingBox[j].start for j in range(len(BoundingBox))])\n",
    "        MaxCoord = np.array([BoundingBox[j].stop for j in range(len(BoundingBox))])\n",
    "\n",
    "        # find the distance between the two vertex coordinates\n",
    "        ApproxLongestAxis = np.linalg.norm(MaxCoord - MinCoord)\n",
    "\n",
    "        # add the approximated axis to np.array\n",
    "        # multiply value by 0.017 because each voxel is 0.017 mm\n",
    "        BBLongestAxes[i] = ApproxLongestAxis * 0.017\n",
    "\n",
    "        # print(f\"Grain {i}: approx longest axis = {ApproxLongestAxis if ApproxLongestAxis > 0 else 'N/A'}\")\n",
    "\n",
    "    return BBLongestAxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2900da92-1ac9-4d1b-a0a1-8d230e593d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# assigning the BBLongestAxis output to a variable\n",
    "BBLongestAxes = BBLongestAxis(NumLabel, BoundingBoxes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33f4a6df-48c3-44c5-a905-5d88801a42d4",
   "metadata": {},
   "source": [
    "Compute the actual longest axis of every particle:\n",
    "-------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feb46c97-f250-4e9b-acfc-9cddb4c202bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# counting the grain voxels within a bounding box (NOT an approximation):\n",
    "# note: requires even more memory than labeling every particle\n",
    "\n",
    "def LongestAxis(NumLabel, BoundingBoxes):\n",
    "    '''\n",
    "        This function calculates the longest axis of each particle by counting the\n",
    "        euclidean distance between each voxel assigned to the same particle\n",
    "        input:\n",
    "            NumLabel: 'float'\n",
    "                the number of labeled particles\n",
    "            BoundingBoxes: list of tuples\n",
    "                a list of coordinates for the bounding boxes\n",
    "        output:\n",
    "            LongestAxes: np.ndarray\n",
    "                stores the longest axis of each particle\n",
    "    '''\n",
    "    \n",
    "    # initialize an array to add largest axes calculations\n",
    "    LongestAxes = np.zeros(NumLabel)\n",
    "    \n",
    "    # loop through each bounding box region\n",
    "    for i, BoundingBox in enumerate(BoundingBoxes):\n",
    "    \n",
    "        # if bounding box is empty, move to the next bounding box\n",
    "        if BoundingBox is None:\n",
    "            continue\n",
    "            \n",
    "        # define the region of the bounding box\n",
    "        BoundedRegion = ParticleLabelCube[BoundingBox]\n",
    "        # find the grain coordinates inside of the bounding box\n",
    "        ParticleCoord = np.column_stack(np.nonzero(BoundedRegion))\n",
    "        \n",
    "        # ignore no voxel grains or grains with only one voxel\n",
    "        if ParticleCoord.shape[0] <= 1:\n",
    "            continue\n",
    "        \n",
    "        # determine the pairwise distances between every grain voxel in the bounding box\n",
    "        VoxelDistances = pdist(ParticleCoord, metric='euclidean')\n",
    "\n",
    "        # loop through every pairwise distance found\n",
    "        if VoxelDistances.size > 0:  # ensures that there are distances\n",
    "            LongestAxes[i] = np.max(VoxelDistances) * 0.017  # adds the largest distance to the list of longest axes\n",
    "\n",
    "        # print(f\"Grain {i}: {GrainCoord.shape[0]} voxels, max distance = {np.max(VoxelDistances) if VoxelDistances.size > 0 else 'N/A'}\")\n",
    "    \n",
    "    return LongestAxes\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d53cc19-b5c1-4bb3-b807-c22bb246b2d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# assigning the LongestAxis output to a variable\n",
    "LongestAxes = LongestAxis(NumLabel, BoundingBoxes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "735a99e9-a2cc-423b-bc80-ba3aff78ba28",
   "metadata": {},
   "source": [
    "# PLOTTING THE PSFD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a03e478a-ad76-4bc4-aa93-369d3a09ad25",
   "metadata": {},
   "source": [
    "Define the power-law function:\n",
    "-----------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20d03afd-3c37-4605-abc5-68adf686bf54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def PowerLaw(x, a, b):\n",
    "    '''\n",
    "        This function computes the power law of a given data set\n",
    "        inputs:\n",
    "            x: np.array\n",
    "                the data (longest axes of particles)\n",
    "            a: float\n",
    "                the y-intercept of the power-law fit\n",
    "            b: float\n",
    "                the slope of the power-law fit\n",
    "        outputs: \n",
    "            PL: float\n",
    "                the power law\n",
    "    '''\n",
    "    \n",
    "    PL = a * x ** b\n",
    "\n",
    "    return PL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0020b1a0-dcbd-434b-aa30-fd966deb9cf6",
   "metadata": {},
   "source": [
    "Determine error:\n",
    "---------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04e1a456-951f-4783-9b3d-dd2e9f980df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# may include in plotting code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d34d815-79d7-4490-81ed-e9595d50eef8",
   "metadata": {},
   "source": [
    "# APPROXIMATION:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6266e436-6201-4c40-80a8-adf6033babb4",
   "metadata": {},
   "source": [
    "Plot the approximated PSFD for ilastik:\n",
    "--------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59b90d3b-4f50-4d54-8eed-21724a79a4f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NO ERROR CALCULATION\n",
    "\n",
    "# hard-code total analyzed volume of the sample\n",
    "# used to normalize the counts\n",
    "SampleVolume = 5e4   # in mm^3\n",
    "\n",
    "# define the x-range for fitting the linear slope accurately\n",
    "xmin_fit = 0.5\n",
    "xmax_fit = 2.0\n",
    "\n",
    "# create log-spaced bins for histogram plotting\n",
    "bins = np.logspace(np.log10(min(BBLongestAxes)), np.log10(max(BBLongestAxes)), 10000)\n",
    "counts, BinEdges = np.histogram(BBLongestAxes, bins=bins)\n",
    "# determining the cumulative sum from the smallest to the largest particle\n",
    "CumulativeCounts = np.cumsum(counts[::-1])[::-1] / SampleVolume  # per mm³\n",
    "BinCenters = (BinEdges[:-1] + BinEdges[1:]) / 2\n",
    "\n",
    "# ignore zeros in the counts due to loglog space\n",
    "mask = CumulativeCounts > 0\n",
    "x = BinCenters[mask]\n",
    "y = CumulativeCounts[mask]\n",
    "\n",
    "# mask the data to be within the selected x-range for accurate fitting\n",
    "# used to find the slope only based on the portion of the plot that is linear\n",
    "mask2 = (x >= xmin_fit) & (x <= xmax_fit)\n",
    "x_fit = x[mask2]\n",
    "y_fit = y[mask2]\n",
    "\n",
    "# fit the curve to the dataset\n",
    "parameters, _ = curve_fit(PowerLaw, x_fit, y_fit, p0=[0.12, -2])\n",
    "a, b = parameters\n",
    "\n",
    "# compute y=mx+b line for slope\n",
    "x_line = np.logspace(np.log10(xmin_fit), np.log10(xmax_fit), 100)\n",
    "y_line = PowerLaw(x_line, a, b)\n",
    "\n",
    "# plot the PSFD\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.loglog(x, y, 'o', ms=1, label='Cumulative Number\\nof Particles', color='black')\n",
    "# highlight portion of the data that contributes to the slope\n",
    "plt.loglog(x_fit, y_fit, 'o', ms=1, color='yellowgreen')\n",
    "plt.loglog(x_line, y_line, ls='--', ms=10, label=f\"Slope = {b:.2f}\", color='green')\n",
    "# labels and organization\n",
    "plt.xlabel(\"BB Longest Axis (mm)\", fontsize=13).set_style('italic')\n",
    "plt.ylabel(f\"Cumulative Frequency per $mm^3$\", fontsize=13).set_style('italic')\n",
    "plt.title(\"Appromixated Particle Size Frequency Distribution\\n for sample OREX-800107-0 using Ilastik\", fontsize=14, weight='bold')\n",
    "plt.grid(True, which='both', linestyle=':', linewidth=0.5)\n",
    "plt.axvline(x = xmin_fit, color = 'black', linestyle='--')\n",
    "plt.axvline(x = xmax_fit, color = 'black', linestyle='--')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig('PSFD_OREX-800107-0_ilastik_boundingbox.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef3a3dc5-912c-42db-bcf1-a4cb2447855c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CALCULATING ERROR WITH BOOTSTRAP METHOD FROM CLAUSSET ET AL.\n",
    "\n",
    "# hard-code total volume of the sample (approximated)\n",
    "SampleVolume = 5e4  # in mm^3\n",
    "\n",
    "# define the x-range for fitting the linear slope accurately\n",
    "xmin_fit = 0.3\n",
    "xmax_fit = 3.0\n",
    "\n",
    "# create log-spaced bins for histogram plotting\n",
    "bins = np.logspace(np.log10(min(BBLongestAxes)), np.log10(max(BBLongestAxes)), 10000)\n",
    "BinEdges, _ = np.histogram(BBLongestAxes, bins=bins)\n",
    "# determine the cumulative sum from the smallest to the largest particle\n",
    "CumulativeCounts = np.cumsum(BinEdges[::-1])[::-1] / SampleVolume  # per mm³\n",
    "BinCenters = (bins[:-1] + bins[1:]) / 2\n",
    "\n",
    "# remove zero counts to avoid log errors\n",
    "mask = CumulativeCounts > 0\n",
    "x = BinCenters[mask]\n",
    "y = CumulativeCounts[mask]\n",
    "\n",
    "# mask the values for the slope to those previously defined\n",
    "mask2 = (x >= xmin_fit) & (x <= xmax_fit)\n",
    "x_fit = x[mask2]\n",
    "y_fit = y[mask2]\n",
    "\n",
    "# fit original data to get initial slope\n",
    "parameteres, _ = curve_fit(PowerLaw, x_fit, y_fit, p0=[0.1, -2.1])\n",
    "a_fit, b_fit = parameters\n",
    "\n",
    "# compute the slope line for plotting\n",
    "x_line = np.logspace(np.log10(xmin_fit), np.log10(xmax_fit), 100)\n",
    "y_line = PowerLaw(x_line, a_fit, b_fit)\n",
    "\n",
    "# loop through slope values to find uncertainty\n",
    "B = 1000  # use at least 5000 for jounral accuracy\n",
    "BootstrapSlopes = []\n",
    "\n",
    "for i in range(B):\n",
    "    # create a randomized data set\n",
    "    # less biased towards one part of the data\n",
    "    sample = np.random.choice(BBLongestAxes, size=len(BBLongestAxes), replace=True)\n",
    "    \n",
    "    # compute histogram and cumulative counts with randomized data\n",
    "    bins = np.logspace(np.log10(min(sample)), np.log10(max(sample)), 10000)\n",
    "    BinEdges, i = np.histogram(sample, bins=bins)\n",
    "    CumulativeCounts = np.cumsum(BinEdges[::-1])[::-1] / SampleVolume\n",
    "    BinCenters = (bins[:-1] + bins[1:]) / 2\n",
    "\n",
    "    # ensure there are no zero counts for log space\n",
    "    mask3 = CumulativeCounts > 0\n",
    "    x_bootstrap = BinCenters[mask3]\n",
    "    y_bootstrap = CumulativeCounts[mask3]\n",
    "\n",
    "    # ensure the x and y values are within the ranges for best-fit\n",
    "    mask4 = (x_bootstrap >= xmin_fit) & (x_bootstrap <= xmax_fit)\n",
    "    x_fit_bootstrap = x_bootstrap[mask4]\n",
    "    y_fit_bootstrap = y_bootstrap[mask4]\n",
    "\n",
    "    # try to fit the above power law to the bootstrap data\n",
    "    try:\n",
    "        parameters_bootstrap, _ = curve_fit(PowerLaw, x_fit_bootstrap, y_fit_bootstrap, p0=[0.1, -2.1])\n",
    "        a_bootstrap, b_bootstrap = parameters_bootstrap\n",
    "        BootstrapSlopes.append(b_bootstrap)\n",
    "    # if the fit fails, move to the next bootstrap value\n",
    "    except:\n",
    "        continue \n",
    "\n",
    "# convert list to np array\n",
    "BootstrapSlopes = np.array(BootstrapSlopes)\n",
    "mean_slope = np.mean(BootstrapSlopes)\n",
    "# define confidence intervals\n",
    "# will determine the +/- error for the slope\n",
    "confidence_lower = np.percentile(BootstrapSlopes, 2.5)  # can change these percentiles\n",
    "confidence_upper = np.percentile(BootstrapSlopes, 97.5)\n",
    "\n",
    "# plot the PSFD\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.loglog(x, y, '.', ms=1, label='Cumulative Number\\nof Particles', color='black')\n",
    "# highlight the region of the data that corresponds to the best-fit slope\n",
    "plt.loglog(x_fit, y_fit, 'o', ms=1, color='yellowgreen')\n",
    "\n",
    "# plot best fit slope with bootstrap uncertainty\n",
    "plt.loglog(x_line, y_line, '--', ms=5, \n",
    "           label=f\"Slope = {b_fit:.2f}\\n95% confidence interval: [{confidence_lower:.2f}, {confidence_upper:.2f}]\", color='green')\n",
    "\n",
    "# labels and organization\n",
    "plt.xlabel('BB Longest Axis (mm)', fontsize=13).set_style('italic')\n",
    "plt.ylabel('Cumulative Frequency per mm$^3$', fontsize=13).set_style('italic')\n",
    "plt.title(\"Approximated Particle Size Frequency Distribution\\nfor Sample OREX-800107-0 Using Ilastik\", fontsize=14, weight='bold')\n",
    "plt.grid(which='both', linestyle=':', linewidth=0.5)\n",
    "plt.axvline(x = xmin_fit, color = 'black', linestyle='--')\n",
    "plt.axvline(x = xmax_fit, color = 'black', linestyle='--')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig('PSFD_OREX-800107-0_ilastik_boundingbox_bootstrap.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2de490a-f400-4bb3-b360-5fcabe32aade",
   "metadata": {},
   "source": [
    "Determine the number of particles for each size range (approximated):\n",
    "-----------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76c691b3-3459-49e2-9a97-9edd5172815d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define bins for the particle size range\n",
    "# 0.01 mm is roughly 1 voxel\n",
    "bins = [0.01, 0.02, 0.03, 0.05, 0.07, 0.1, 0.2, 0.5, 0.8, 1.0, 2.0, 3.0, 5.0, 12.0]  \n",
    "labels = [f\"{bins[i]}-{bins[i+1]}\" for i in range(len(bins) - 1)]\n",
    "\n",
    "# count the number of particles in each bin\n",
    "counts, _ = np.histogram(BBLongestAxes, bins=bins)\n",
    "\n",
    "# create table data\n",
    "table = list(zip(labels, counts))\n",
    "\n",
    "print(tabulate(table, headers=[\"Size Range (mm)\", \"Number of Particles\"], tablefmt=\"simple\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72992687-1727-434d-b029-6c1d9aa82aa9",
   "metadata": {},
   "source": [
    "# ACTUAL:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfd50376-507f-4026-9661-9b15ba4cd35f",
   "metadata": {},
   "source": [
    "Plot the actual PSFD for ilastik:\n",
    "--------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea13a876-f28f-4afc-aa37-eef48b8d4378",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NO ERROR CALCULATION\n",
    "\n",
    "# hard-code total analyzed volume of the sample\n",
    "# used to normalize the counts\n",
    "SampleVolume = 5e4   # in mm^3\n",
    "\n",
    "# define the x-range for fitting the linear slope accurately\n",
    "xmin_fit = 0.3\n",
    "xmax_fit = 5.0\n",
    "\n",
    "# create log-spaced bins for histogram plotting\n",
    "bins = np.logspace(np.log10(min(LongestAxes)), np.log10(max(LongestAxes)), 10000)\n",
    "counts, BinEdges = np.histogram(LongestAxes, bins=bins)\n",
    "# determining the cumulative sum from the smallest to the largest particle\n",
    "CumulativeCounts = np.cumsum(counts[::-1])[::-1] / SampleVolume  # per mm³\n",
    "BinCenters = (BinEdges[:-1] + BinEdges[1:]) / 2\n",
    "\n",
    "# ignore zeros in the counts due to loglog space\n",
    "mask = CumulativeCounts > 0\n",
    "x = BinCenters[mask]\n",
    "y = CumulativeCounts[mask]\n",
    "\n",
    "# mask the data to be within the selected x-range for accurate fitting\n",
    "# used to find the slope only based on the portion of the plot that is linear\n",
    "mask2 = (x >= xmin_fit) & (x <= xmax_fit)\n",
    "x_fit = x[mask2]\n",
    "y_fit = y[mask2]\n",
    "\n",
    "# fit the curve to the dataset\n",
    "parameters, _ = curve_fit(PowerLaw, x_fit, y_fit, p0=[0.12, -2])\n",
    "a, b = parameters\n",
    "\n",
    "# compute y=mx+b line for slope\n",
    "x_line = np.logspace(np.log10(xmin_fit), np.log10(xmax_fit), 100)\n",
    "y_line = PowerLaw(x_line, a, b)\n",
    "\n",
    "# plot the PSFD\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.loglog(x, y, 'o', ms=1, label='Cumulative Number\\nof Particles', color='black')\n",
    "# highlight portion of the data that contributes to the slope\n",
    "plt.loglog(x_fit, y_fit, 'o', ms=1, color='yellowgreen')\n",
    "plt.loglog(x_line, y_line, ls='--', ms=10, label=f\"Slope = {b:.2f}\", color='green')\n",
    "# labels and organization\n",
    "plt.xlabel(\"Longest Axis (mm)\", fontsize=13).set_style('italic')\n",
    "plt.ylabel(f\"Cumulative Frequency per $mm^3$\", fontsize=13).set_style('italic')\n",
    "plt.title(\"Particle Size Frequency Distribution\\n for sample OREX-800107-0 using Ilastik\", fontsize=14, weight='bold')\n",
    "plt.grid(True, which='both', linestyle=':', linewidth=0.5)\n",
    "plt.axvline(x = xmin_fit, color = 'black', linestyle='--')\n",
    "plt.axvline(x = xmax_fit, color = 'black', linestyle='--')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig('PSFD_OREX-800107-0_ilastik.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4de2135e-44b9-4ac8-92db-26d5da5331d7",
   "metadata": {},
   "source": [
    "Determine the number of particle of each size range (actual):\n",
    "---------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d178970b-5c35-4f7d-8381-507051bc1c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define bins for the particle size range\n",
    "bins = [0.01, 0.05, 0.1, 0.2, 0.5, 0.8, 1.0, 2.0, 3.0, 5.0, 7.0]  \n",
    "labels = [f\"{bins[i]}-{bins[i+1]}\" for i in range(len(bins) - 1)]\n",
    "\n",
    "# count the number of particles in each bin\n",
    "counts, _ = np.histogram(LongestAxes, bins=bins)\n",
    "\n",
    "# create table data\n",
    "table = list(zip(labels, counts))\n",
    "\n",
    "print(tabulate(table, headers=[\"Size Range (mm)\", \"Number of Particles\"], tablefmt=\"simple\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
